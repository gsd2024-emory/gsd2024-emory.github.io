<!DOCTYPE html>
<html lang='en'>

<head>
    <base href="..">
    <link rel="shortcut icon" type="image/png" href="assets/favicon.png" />
    <link rel="stylesheet" type="text/css" media="all" href="assets/main.css" />
    <meta name="description" content="Georgia Statistics Day 2024">
    <meta name="resource-type" content="document">
    <meta name="distribution" content="global">
    <meta name="KeyWords" content="Georgia Statistics Day, GSD, Conference">
    <title>Georgia Statistics Day 2024</title>
    <meta name="viewport" content="user-scalable=yes">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
</head>

<body>

    <div class="banner">
        <img style="width:100%; display:block" src="assets/frontpage.jpg" alt="Conference Template Banner">
        <div class="top-left">
            <span class="title1">Georgia</span><span class="title1"> Statistics Day</span> <span
                class="year">2024</span>
        </div>
        <div class="bottom-right">
            October 25th, 2024 <br> Emory University
        </div>
    </div>

    <!-- <table class="navigation">
        <tr>
            <td class="navigation">
                <a title="Conference Home Page" href=".">Home</a>
            </td>
            <td class="navigation">
                <a title="Register for the Conference" href="registration">Registration</a>
            </td>
            <td class="navigation">
                <a title="Conference Speaker" href="speaker">Speaker</a>
            </td>
            <td class="navigation">
                <a title="Conference Program" href="program">Program</a>
            </td>
            <td class="navigation">
                <a class="current" title="Conference Abstract" href="abstract">Abstract</a>
            </td>
            <td class="navigation">
                <a title="Conference Poster Sessions" href="poster">Poster</a>
            </td>
            <td class="navigation">
                <a title="Directions to the Conference" href="directions">Directions</a>
            </td>
            <td class="navigation">
                <a title="Conference Sponsor" href="sponsor">Sponsors</a>
            </td>
        </tr>
    </table> 
<br>
-->

	
    <div class="topnav" id="myTopnav">
        <a href=".">Home</a>
        <a href="registration">Registration</a>
        <a href="speaker">Speakers</a>
        <a href="program">Program</a>
        <a href="abstract" class="active">Abstracts</a>
        <a href="poster">Posters</a>
        <a href="directions">Direction</a>
        <a href="sponsor">Sponsors</a>
        <a href="javascript:void(0);" class="icon" onclick="myFunction()">
            <i class="fa fa-bars"></i>
        </a>
    </div>

    <br>

    <div style="margin:2%; padding:2%">
TBC
<!--	    
        <h3>Keynote Talk</h3>

        <hr>

        <hr>

        <hr>

        <h4 id="AnnieQu" class="title">TBD</h4>
        <p class="abname"><strong>Speaker: </strong><a
                href="https://www.stat.uci.edu/faculty/annie-qu/" target="_blank"
                rel="noopener noreferrer">Annie Qu</a> </p>
        <p class="abstract"><strong>Abstract: </strong> </p>
        <p> TBC
        </p>
        <p class="abstract"><strong>Biography: </strong> </p>
        <p> TBC
        </p>

        <hr>

        <hr>

        <hr>

        <h3>Invited Speakers</h3>

        <hr>

        <hr>

        <hr>

        <h4 id="DonaldLee" class="title">
		  Boosted generalized normal distributions: Forecasting patient wait and service times in emergency departments
        </h4>
        <p class="abname"><strong>Speaker: </strong><a>Donald Lee</a> </p>
        <p class="abstract"><strong>Abstract: </strong> </p>
        <p>Applications of ML techniques sometimes ignore important knowledge from the domain it is applied to. For example, it is known that the distribution of patient wait times in an emergency department (ED) is approximately exponential, but current wait time forecasts ignore this information. To incorporate distributional knowledge into ML forecasts, we introduce a rigorous tree boosting procedure for estimating generalized normal distributions (bGND). We show that bGND performs 6% better than the distribution-agnostic ML benchmark in the distributional forecasting of patient wait times, which translates into a 9% increase in patient satisfaction and an increase in hospital earnings of $120,000 for every 10,000 visits. Similar improvements are also shown for patient service time forecasts using bGND. 
        </p>

	 <p class="abstract"><strong>Biography: </strong> </p>
        <p> Prof. Lee's research develops rigorous data science techniques for improving the delivery of health care. On the applied front, he has extensive experience designing data-driven tools for problems ranging from healthcare financial planning to real-time warning systems for adverse medical events. On the methodological front, his research has resolved foundational questions in causal inference and in survival machine learning. His work has appeared in leading journals in management, statistical machine learning, and healthcare, and is recognized by R01 funding from the NIH. Prior to joining Emory, he served as an associate professor at Yale and held appointments in the School of Management and in the Department of Statistics & Data Science.
        </p>

        <hr>

	<h4 id="RayBai" class="title">
	    Order Selection for Clustering Multivariate Extremes
        </h4>
        <p class="abname"><strong>Speaker: </strong><a>Ray (Shuyang) Bai</a> </p>
        <p class="abstract"><strong>Abstract: </strong> </p>
        <p>
	    In extreme value theory, the so-called spectral measure summarizes the directional dependence pattern of extreme values across different variables. Several recent works have related spherical clustering techniques to the estimation of models with a discrete spectral measure. Yet, the problem of determining the order, i.e., the number of distinct atoms of the spectral measure, remains unexplored. In this work, we develop an order selection method that, on the theoretical side, consistently recovers the true order, and on the practical side, enjoys intuitive and simple implementation. Our method is based on a variant of the well-known Silhouette method.  In particular, we introduce an additional penalty term to the so-called simplified average silhouette width, which discourages small cluster sizes and small dissimilarities between cluster centers. The optimal order is chosen by visualizing the bending of the penalized average silhouette width curve (as a function of the order selected) when the tuning parameter of the penalty term increases. As a consequence, this method consistently estimates the order of a max-linear factor model, for which an usual information-criterion-based method is not applicable. Simulation studies demonstrate the bias-correcting effect of the penalty introduced. The method is also illustrated on a river discharge data set for stations located throughout the US. The order selected by our method matches the geographical context of these stations. This is a joint work with Shiyuan Deng and He Tang.
        </p>

	 <p class="abstract"><strong>Biography: </strong> </p>
        <p> 
	    Ray (Shuyang) Bai is an associate professor at the Department of Statistics of University of Georgia. He obtained his PhD in Mathematics from Boston University in 2016. His research scope spans across probability and statistics. He is particularly interested in probabilistic and statistical questions related to data exhibiting non-standard scaling features such as long-range dependence and heavy tails. His recent focus includes extreme value theory under dependence, as well as analysis of multivariate extremes through the lens of machine learning techniques.
        </p>

        <hr>

	<h4 id="RuiyanLuo" class="title">
	    Functional Differential Equation Model for Dynamic System
        </h4>
        <p class="abname"><strong>Speaker: </strong><a>Ruiyan Luo</a> </p>
        <p class="abstract"><strong>Abstract: </strong> </p>
        <p>
	    One major limitation of Ordinary Differential Equation (ODE) model is that it assumes the derivatives of the system only depend on the concurrent values. This concurrent assumption can oversimplify the mechanism of dynamic systems and limit the applicability of differential equations.  To address the limitation, we propose a general Functional Differential Equation (FDE) model which allows the derivative to explicitly depend on both the current value and a historical segment of the system through an operator whose form is unknown. The operator maps functions defined in infinite-dimension spaces to scalars. To construct the operator and build the FDE from noisy observations, we propose a new family of estimators, called the Functional Neural Networks (FNN) with a smooth hidden layer, and establish the universal approximation property which states that any operator under mild regularity conditions can be well estimated by the members of this family.   With this theorem, we propose a penalized moving window integrated least squares method to construct an estimate of the FDE and make forecasts. The FDE method displays an obvious advantage in forecasting by simulations and application in sunspot data.
        </p>

	 <p class="abstract"><strong>Biography: </strong> </p>
        <p> 
	    Dr. Ruiyan Luo is Professor of Biostatistics in Department of Population Health Sciences, School of Public Health, Georgia State University. Her research interests include functional data analysis, Bayesian statistics, machine learning, dynamic system modeling and application in infectious diseases. 
        </p>

        <hr>

	<h4 id="YichuanZhao" class="title">
Bayesian Jackknife Empirical Likelihood-based Inference for Missing Data and Causal Inference Problems        </h4>
        <p class="abname"><strong>Speaker: </strong><a>Yichuan Zhao</a> </p>
        <p class="abstract"><strong>Abstract: </strong> </p>
        <p>
	    Missing data reduces the representativeness of the sample and can lead to inference problems. This study applied the Bayesian jackknife empirical likelihood method for inference with missing data that were missing at random and causal inference. The semiparametric fractional imputation estimator, propensity score weighted estimator, and doubly robust estimator were used for constructing the jackknife pseudo values which were needed for conducting Bayesian jackknife empirical likelihood-based inference with missing data. Existing methods, such as normal approximation and jackknife empirical likelihood, were compared with the Bayesian jackknife empirical likelihood approach in a simulation study. The proposed approach had better performance in many scenarios in terms of the behavior of credible intervals. Furthermore, we demonstrated the application of the proposed approach for causal inference problems in a study of risk factors for impaired kidney function.
        </p>

	 <p class="abstract"><strong>Biography: </strong> </p>
        <p> 
	    Dr. Yichuan Zhao is a Professor of Statistics at Georgia State University in Atlanta.  His current research interest focuses on survival analysis, empirical likelihood methods, nonparametric statistics, analysis of ROC curves, bioinformatics, Monte Carlo methods, and statistical modelling of fuzzy systems. He has published more than 100 research articles in statistics and biostatistics, has co-edited six books on statistics, biostatistics and data science, and has been invited to deliver more than 200 research talks nationally and internationally. Dr. Zhao has organized the Workshop Series on Biostatistics and Bioinformatics since its initiation in 2012. He also organized the 25th ICSA Applied Statistics Symposium in Atlanta as the chair of the organizing committee to great success. In addition, the 6th ICSA China Conference that he organized as the chair of both the organizing committee and program committee was a huge success.   Dr. Zhao is a Fellow of the American Statistical Association, an elected member of the International Statistical Institute.
    	</p>

        <hr>

	<h4 id="ID" class="title">
	    TITLE
        </h4>
        <p class="abname"><strong>Speaker: </strong><a>NAME</a> </p>
        <p class="abstract"><strong>Abstract: </strong> </p>
        <p>
	    ABSTRACT
        </p>

	 <p class="abstract"><strong>Biography: </strong> </p>
        <p> 
	    BIO
    	</p>

        <hr>

        <h4 id="Santu" class="title"> Large-Scale Simultaneous Testing Using Kernel Density Estimation
        </h4>
        <p class="abname"><strong>Speaker: </strong><a
                href="https://www.augusta.edu/mcg/dphs/bds/people/santu_ghosh.php" target="_blank"
                rel="noopener noreferrer">Santu Ghosh</a> </p>
        <p class="abstract"><strong>Abstract: </strong> </p>
        <p> A century ago, when Student's t-statistic was introduced, no one ever imagined its increasing applicability
            in the modern era. It finds applications in highly multiple hypothesis testing, feature selection and
            ranking, high dimensional signal detection, etc. Student's t-statistic is constructed based on the empirical
            distribution function (EDF). An alternative choice to the EDF is the kernel density estimate (KDE), a
            smoothed version of the EDF. The novelty of the work consists of an alternative to Student's t-test that
            uses the KDE technique and exploration of the usefulness of the KDE-based t-test in the context of its
            application to large-scale simultaneous hypothesis testing. An optimal bandwidth parameter for the KDE
            approach is derived by minimizing the asymptotic error between the true p-value and its asymptotic estimate
            based on normal approximation. We compare our method to several possible alternatives with respect to the
            false discovery rate. We show in simulations that our method produces a lower proportion of false
            discoveries than its competitors. The usefulness of the proposed methods is further illustrated through a
            gene expression data example.
        </p>

        <hr>

        <h4 id="Linwei" class="title"> Fitting interpretable Machine Learning models with main effect and low-order
            interactions using boosted model-based trees
        </h4>
        <p class="abname"><strong>Speaker: </strong><a>Linwei Hu</a>
        </p>
        <p class="abstract"><strong>Abstract: </strong> </p>
        <p> There is a great deal of interest recently on machine learning interpretability, especially in regulated
            industries where one needs to understand and explain the results to various stakeholders. This talk presents
            a method called GAMI-Tree for developing inherently-interpretable machine learning models. It is based on a
            functional ANOVA decomposition of the model and estimating just the main effects and low-order interactions.
            While this concept is known in statistics, the challenge is to develop fast and scalable algorithms to do
            non-parametric estimation with large datasets. Explainable boosting machine (EBM) was proposed in Lou et al.
            (2013) to address this challenge. Unlike EBM, GAMI-Tree uses customized model-based trees and performs as
            all as, or better than, EBM on simulated and real data sets. In addition, GAMI-Tree is better in capturing
            interaction effects as it uses more flexible base learner.
        </p>

        <hr>

        <h4 id="Pengsheng" class="title">Statistics for Statisticians: Looking into the Past through Citations
        </h4>
        <p class="abname"><strong>Speaker: </strong><a href="https://www.stat.uga.edu/directory/people/pengsheng-ji"
                target="_blank" rel="noopener noreferrer">Pengsheng Ji</a> </p>
        <p class="abstract"><strong>Abstract: </strong> </p>
        <p> We have a new dataset covering about 80K statistical papers published in the last 40 years and use it to
            study a few aspects of the field of statistics through citations. First, we present the dynamic ranking of
            statistics journals using the Stigler model and PageRank. Second, we predict the highly cited papers using
            logistic model and G. boost and identify the most important features of these papers.

        </p>

        <hr>


        <h4 id="Wenjing" class="title"> Exploiting low-dimensional structures of data sets in machine learning with deep
            neural networks
        </h4>
        <p class="abname"><strong>Speaker: </strong><a href="https://people.math.gatech.edu/~wliao60/" target="_blank"
                rel="noopener noreferrer">Wenjing Liao</a> </p>
        <p class="abstract"><strong>Abstract: </strong> </p>
        <p> Many data in real-world applications are in a high-dimensional space but exhibit low-dimensional structures.
            In mathematics, these data can be modeled as random samples on a low-dimensional manifold. Our goal is to
            estimate a target function or a nonlinear operator between infinite dimensional function spaces by neural
            networks. This talk is based on an efficient approximation theory of deep ReLU networks for functions
            supported on a low-dimensional manifold. We further establish the sample complexity for regression and
            operator estimation with finite samples of data. When data are sampled on a low-dimensional manifold, the
            sample complexity crucially depends on the intrinsic dimension of the manifold instead of the ambient
            dimension of the data. These results demonstrate that deep neural networks are adaptive to low-dimensional
            geometric structures of data sets.


        </p>

        <hr>



        <h4 id="Ruiyan" class="title"> Modeling spiky functions with derivatives of smooth functions in
            function-on-function regression
        </h4>
        <p class="abname"><strong>Speaker: </strong><a href="https://publichealth.gsu.edu/profile/ruiyan-luo/"
                target="_blank" rel="noopener noreferrer">Ruiyan Luo</a> </p>
        <p class="abstract"><strong>Abstract: </strong> </p>
        <p> Smoothness penalty is an efficient regularization and dimension reduction tool for functional regression.
            However, for spiky functional data observed on a dense grid, the coefficient function in functional
            regression can be spiky and hence the smoothness regularization is inefficient and leads to over-smoothing.
            We propose a novel approach to fit the functional-on-function regression model by viewing the spiky
            coefficient functions as the derivatives of smooth auxiliary functions. Compared to smoothness
            regularization or sparsity regularization which are imposed directly on the spiky coefficient function in
            existing methods, imposing smoothness regularization on the smooth auxiliary functions can more efficiently
            reduce the dimension and improve the performance of fitted model. With the estimated smooth auxiliary
            functions and by taking derivatives, we can fit the model and make prediction. Simulation studies and real
            data applications show that compared to the existing methods, the new method can greatly improve model
            performance when the coefficient function is spiky, and performs similarly well when the coefficient
            function is smooth.
        </p>


        <hr>




        <h4 id="Christina" class="title">Nested and Multipart Studies: Flaming Fiasco or Efficiently Economical?
        </h4>
        <p class="abname"><strong>Speaker: </strong><a
                href="https://sph.emory.edu/faculty/profile/index.php?FID=c.%20christina-mehta-837" target="_blank"
                rel="noopener noreferrer">Christina Mehta</a> </p>
        <p class="abstract"><strong>Abstract: </strong> </p>
        <p> "Nested" and "multipart" studies are two ways of expanding the scope of a research program beyond what might
            otherwise be possible with available funding. Nested studies are cost-effective because they leverage the
            parent study infrastructure and personnel within which they are cocooned. Multipart studies are
            cost-effective because they leverage the same cohort of participants for use in interlinked research studies
            that share common components. There is little information on the practical implications of either nested or
            multipart study designs. This proposal will describe the real-world advantages, disadvantages, and important
            considerations of nested and multipart studies and highlight experiences gained from leading the statistical
            aspects of a complex nested, multipart study on whether estrogen insufficiency-induced inflammation
            leverages HIV-induced inflammation to cause end organ damage and worsen age-related co-morbidities affecting
            the neuro-hypothalamic-pituitary-adrenal axis (brain), musculoskeletal (bone), and cardiovascular organ
            systems (heart; BBH study) conducted by the Specialized Center for Research Excellence on Sex Differences
            (SCORE) at Emory University.

        </p>

        <hr>


        <h4 id="Mohamed" class="title"> How Social Vulnerability Predicted the Frequency and Intensity of COVID-19 A
            case in point using Georgia county-specific data
        </h4>
        <p class="abname"><strong>Speaker: </strong><a
                href="https://www.msm.edu/about_us/FacultyDirectory/CommunityHealthPreventiveMedicine/MohamedMubasher/index.php"
                target="_blank" rel="noopener noreferrer">Mohamed
                Mubasher</a> </p>
        <p class="abstract"><strong>Abstract: </strong> </p>
        <p> Racial disparity adversely impacts COVID-19 infection and fatality rates. Hospitalization rates due to the
            pandemic among African Americans/Latinx/Hispanics in Georgia have been among the highest in the nation.
            Sociopolitical determinants also termed Social Vulnerability have been identified as one of the main factors
            plaguing minorities on the face of the burden of the pandemic. Social Vulnerability Index (SVI) was
            developed by ATSDR at CDC . The basic formula projects how disaster unfolds: "(Risk = Hazard *
            (Vulnerability - Resources) where Risk is the likelihood or expectation of loss; Hazard is a condition
            posing the threat of harm; Vulnerability is the extent to which persons or things are likely to be affected;
            and Resources are those assets in place that will diminish the effects of hazards" (Dwyer et al. 2004; UCLA
            Center for Public Health and Disasters 2006). Using census-tract-specific percentile ranks, SVI was
            developed taking into account four domains including socioeconomic status, household composition, minority
            status and language and housing type and transportation. Along with SVI, we used GA Department of Public
            Health, CDC data and County Health Rankings & Roadmaps specific statistics to cross-sectionally and
            longitudinally employ (Poisson) Generalized Linear Mixed Models to functionally relate infection/death rates
            vis-a-vis % racial population difference (60+years %whites - %African Americans (AA)/Blacks), education,
            unemployed, uninsured, % obese and racial differences in respiratory infection discharge rates. We
            additionally but separately also modeled county-specific frequency and intensity of COVID-19 up to August
            30, 2021 as function of SVI, comorbid conditions, % obese, vaccination rates and insurance status. Analyses
            also evaluated the sensitivity of SVI in predictive models in lieu of socioeconomic variables
            (ethnicity/race, income, education, gender and age). Results revealed the magnitude and the significance of
            the burden posed by social vulnerability in response to the outbreak of the SARS-CoV-2 pandemic. Older age,
            male gender, AA /other minority group, presence of comorbid conditions, obesity and lower vaccination rates
            also independently but adversely predicted higher COVID-19 infection and related mortality rates. SVI
            significantly correlated with these findings.
        </p>

        <hr>



        <h4 id="Razieh" class="title"> The role of causal mediation analysis in personalized decision making
        </h4>
        <p class="abname"><strong>Speaker: </strong><a href="https://www.cs.jhu.edu/~rnabi/" target="_blank"
                rel="noopener noreferrer">Razieh Nabi</a> </p>
        <p class="abstract"><strong>Abstract: </strong> </p>
        <p> In practice, clinicians synthesize information on patient characteristics, such as medical history and life
            style, to tailor a sequence of treatment decisions for the patient. The goal of precision medicine is to
            make this clinical decision-making process evidence-based, and find optimal treatment rules to maximize the
            likelihood of desirable outcomes. Unfortunately, the full benefit of a treatment regime may not be realized
            since patients often do not fully adhere to the treatment plan due to toxic side effects of the medication.
            In this talk, we describe how we can combine tools from causal inference, mediation analysis, and
            reinforcement learning to account for differential adherence while learning high quality policies and
            decision rules.
        </p>

        <hr>

        <h4 id="Ben">A missing data method for deconfounding in neuroimaging studies</h4>
        <p><strong>Speaker: </strong><a
                href="https://sph.emory.edu/faculty/profile/index.php?FID=benjamin%20-risk%20-8915" target="_blank"
                rel="noopener noreferrer">Ben
                Risk</a> </p>
        <p><strong>Abstract: </strong> </p>
        <p>Resting-state fMRI studies remove participants that fail motion quality control criteria. Motion is
            particularly problematic in studies on children and neurodevelopmental disorders, including autism spectrum
            disorder (ASD). In ASD studies, popular motion quality control criteria result in the removal of the
            majority of children. Moreover, children with more severe ASD are more likely to be excluded. To address the
            sampling bias, we define a target parameter for the difference in functional connectivity between ASD and
            typically developing children. We call this target parameter the deconfounded group difference, which
            utilizes the distribution of diagnosis-specific behavioral variables across usable and unusable scans. We
            estimate the deconfounded group difference using doubly robust targeted minimum loss-based estimation with
            an ensemble of machine learning methods for the propensity and outcome models. In a study of ASD and
            typically developing children, we find more extensive differences than the naive estimator. Our findings
            suggest the deconfounded group difference can reveal the pathophysiology of neurological disorders in
            populations with high motion.
        </p>

        <hr>



        <h4 id="Heather">Modernizing CDC's data and IT infrastructure to accelerate the adoption of advanced statistical
            methods</h4>
        <p><strong>Speaker: </strong><a>Heather Strosnider</a> </p>
        <p><strong>Abstract: </strong> </p>
        <p>CDC and its public health partners are undergoing a transformative data modernization to move from siloed and
            brittle public health data systems to connected, resilient, adaptable, and sustainable "response-ready"
            systems that can help us solve problems before they happen and reduce the harm caused by the problems that
            do happen. This transformation aims to build a new digital infrastructure with increased data access, data
            harmonization, and shared tools and services to support the data lifecycle. The new digital infrastructure
            will allow public health to leverage advanced statistical methods such as machine learning. With modernized
            digital infrastructure, public health will be better able to monitor the complex, interconnected dimensions
            of health and to predict and forecast future pandemics and non-infectious threats. This presentation will
            describe CDCâ€™s data modernization strategy and vision.
        </p>

        <hr>



        <h4 id="Shihao" class="title"> Big-data infectious disease estimation: From flu to covid-19
        </h4>
        <p class="abname"><strong>Speaker: </strong><a href="https://www.isye.gatech.edu/users/shihao-yang"
                target="_blank" rel="noopener noreferrer">Shihao Yang</a> </p>
        <p class="abstract"><strong>Abstract: </strong> </p>
        <p> For epidemics control and prevention, timely insights of potential hot spots are invaluable. An alternative
            to traditional epidemic surveillance, which often lags behind real-time by days or even weeks, big data from
            the Internet provide important information about the current epidemic trends. We will present a few big-data
            approaches for influenza prediction, and how the approaches are applied to covid-19 prediction in the
            current pandemic.
        </p>
        <p class="abstract"><strong>Biography: </strong> </p>
        <p> Dr. Shihao Yang is an assistant professor in School of Industrial & Systems Engineering at Georgia Tech.
            Prior to joining Georgia Tech, he was a post-doc in Biomedical Informatics at Harvard Medical School after
            finishing his PhD in statistics from Harvard University. Dr. Yang's research focuses on data science for
            healthcare, with special interest in big-data infectious disease prediction, and electronic health records.
        </p>

        <hr>

        <h4 id="Yonggang" class="title">Counterfactual Analysis of Cross-Sectional Data Using Quantile Process
            Regression</h4>
        <p class="abname"><strong>Speaker: </strong><a>Yonggang
                Yao</a> </p>
        <p class="abstract"><strong>Abstract: </strong> </p>
        <p>This work illustrates how you can apply quantile process regression (QPR) to perform counterfactual analysis
            for cross-sectional data. QPR builds the probability distribution model for a response variable conditional
            on its associated explanatory covariates by fitting quantile regression models in the entire quantile-level
            range from 0 to 1. For cross-sectional treatment-control comparison studies, you can use QPR to predict
            counterfactual distributions of the responses for the treatment-group subjects. That predictions
            counterfactually assume the treatment-group subjects were in the control group. Because QPR estimates the
            entire response distributions, you can then evaluate treatment effects and
            treatment-control-subjects-selection bias by using a variety of statistical standards such as mean
            difference, median different, and Mann-Whitney-Wilcoxon U test. In addition, when a continuous mediation
            variable is involved, QPR can furthermore predict the distribution of the mediation variable and perform
            causal mediation analysis. This work exemplifies the QPR counterfactual analysis methods by analyzing the
            impact of mothers smoking habits on newborns body weights.
        </p>


        <hr>

        <h4 id="Ting" class="title"> High Quantile Regression for Tail Dependent Time Series
        </h4>
        <p class="abname"><strong>Speaker: </strong><a href="https://www.stat.uga.edu/directory/people/ting-zhang"
                target="_blank" rel="noopener noreferrer">Ting Zhang</a> </p>
        <p class="abstract"><strong>Abstract: </strong> </p>
        <p> Quantile regression serves as a popular and powerful approach for studying the effect of regressors on
            quantiles of a response distribution. However, existing results on quantile regression were mainly developed
            when the quantile level is fixed, and the data are often assumed to be independent. Motivated by recent
            applications, we consider the situation where (i) the quantile level is not fixed and can grow with the
            sample size to capture the tail phenomena; and (ii) the data are no longer independent but collected as a
            time series that can exhibit serial dependence in both tail and non-tail regions. To study the asymptotic
            theory for high quantile regression estimators in the time series setting, we introduce a previously
            undescribed tail adversarial stability condition, and show that it leads to an interpretable and convenient
            framework for obtaining limit theorems for time series that exhibit serial dependence in the tail region but
            are not necessarily strong mixing. Numerical experiments are provided to illustrate the effect of tail
            dependence on high quantile regression estimators, where simply ignoring the tail dependence may lead to
            misleading p-values.
        </p>

        <hr>

        <hr>

        <hr>

        <h3>Round Table Discussions</h3>

        <hr>

        <hr>

        <hr>

        <h4 id="Jacqueline" class="title"> SAS Global Academic Programs: A Corporate Partner to Enable Analytics
            Education
        </h4>
        <p class="abname"><strong>Lead: </strong><a>Jacqueline Johnson</a> </p>
        <p class="abstract"><strong>Abstract: </strong> </p>
        <p> At SAS Global Academic Programs, our primary mission is to support faculty and students with aligning skill
            development to industry demand. We draw on labor market data to understand the current demand for analytics
            and SAS skill and to guide the development of academic resources. During our roundtable, we will discuss the
            free, comprehensive support we provide to faculty members for the learning and teaching of SAS including
            free software access, opportunities for educator training and workshops, curriculum consultations to support
            integration of SAS into the classroom, and joint academic programs.
        </p>

        <hr>

        <h4 id="Tracey" class="title"> Full-time and Internship Opportunities with Wells Fargo
        </h4>
        <p class="abname"><strong>Lead: </strong><a>Tracey Tullie</a> </p>
        <p class="abstract"><strong>Abstract: </strong> </p>
        <p> A representative from Wells Fargo, will lead the discussion and provide details for full-time and internship
            opportunities at Wells Fargo. She will also talk about necessary skills needed to be a successful
            quantitative analyst in Corporate America.
        </p>

        <hr>

-->



    </div>

    <script src="media_function.js"></script>
</body>

</html>
